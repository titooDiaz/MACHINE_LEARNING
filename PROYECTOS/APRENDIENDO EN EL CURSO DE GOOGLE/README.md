<p align="center">
  <img width="150px" src="https://i.ibb.co/bXvzjXm/LOGO-h1.png" />
</p>

# CURSO DE APRENDIZAJE AUTOMATICO HECHO POR GOOGLE

## Tabla de contenido:
1. [Introducci√≥n](#introduction) [üëª](https://developers.google.com/machine-learning/crash-course/ml-intro?hl=es-419)
2. [Generalizacion](#generalizacion) [üëª](https://developers.google.com/machine-learning/crash-course/generalization/video-lecture?hl=es-419)
3. [Representacion](#representacion) [üëª](https://developers.google.com/machine-learning/crash-course/representation/video-lecture?hl=es-419)
4. [Combinacion de Atributos](#combinacion)
5. [Vectores](#vectores)
6. [Regresion logistica](#regresion) [üëª](https://developers.google.com/machine-learning/crash-course/logistic-regression/video-lecture?hl=es-419)
7. [Clasificacion](#clasificaion) [üëª](https://developers.google.com/machine-learning/crash-course/classification/video-lecture?hl=es-419)
8. [Regularizacion](#regularizacion) [üëª](https://developers.google.com/machine-learning/crash-course/regularization-for-sparsity/video-lecture?hl=es-419)
9. [Redes neuronales](#redesneuronales) [üëª](https://developers.google.com/machine-learning/crash-course/introduction-to-neural-networks/video-lecture?hl=es-419)
10. [](#) [üëª]()
11. [](#) [üëª]()
12. [](#) [üëª]()

## Introduccion: <p id="introduction">
Este es un curso hecho por google, donde nos ofrece una amplia informacion para informarnos sobre `Tensorflow` su biblioteca de aprendizaje automatico
Igualemente utilizaremos otras tecnologias, como numPy y Pandas

[Curso que veremos](https://developers.google.com/machine-learning/crash-course/ml-intro?hl=es-419)
[Cursos Basicos](https://developers.google.com/machine-learning?hl=es-419)

# TENSORFLOW
A medida que avances en el Curso intensivo de aprendizaje autom√°tico, podr√°s poner en pr√°ctica los conceptos del aprendizaje autom√°tico mediante la codificaci√≥n de modelos en tf.keras. Usar√°s Colab como entorno de programaci√≥n. Colab es la versi√≥n de Google de Notebook de Jupyter. Al igual que el notebook de Jupyter, Colab proporciona un entorno interactivo de programaci√≥n de Python que combina texto, c√≥digo, gr√°ficos y resultados del programa.

## NumPy y Pandas
El uso de tf.keras requiere, al menos, un poco de comprensi√≥n de las siguientes dos bibliotecas de c√≥digo abierto de Python:

NumPy, que simplifica la representaci√≥n de arrays y la realizaci√≥n de operaciones de √°lgebra lineal. [Numpy](https://numpy.org/)
<br>

pandas, que proporciona una manera f√°cil de representar conjuntos de datos en la memoria. [Pandas](https://pandas.pydata.org/)

Si no est√°s familiarizado con NumPy o Pandas, comienza con los siguientes dos ejercicios de Colab:

Ejercicio de Colab de NumPy UltraQuick Tutorial, que brinda toda la informaci√≥n de NumPy que necesitas para este curso. (NUMPY TUTORIAL)
Ejercicio de Colab sobre el instructivo r√°pido de Pandas, que brinda toda la informaci√≥n que necesitas sobre este curso. (PANDAS TUTORIAL)

<br>

## Generalizacion <p id="generalizacion">
Guillermo de Ockham, un fraile y fil√≥sofo del siglo XIV, amaba la simplicidad. Cre√≠a que los cient√≠ficos deber√≠an preferir lo m√°s simple f√≥rmulas o teor√≠as sobre otras m√°s complejas. Para poner la navaja de Ockham en la m√°quina T√©rminos de aprendizaje:
`Cuanto menos complejo sea un modelo de ML, m√°s probable es que se obtenga un buen resultado emp√≠rico no se debe solo a las peculiaridades de la muestra.`

<br>

Un modelo de aprendizaje autom√°tico tiene como objetivo hacer buenas predicciones sobre datos nunca antes vistos. Pero si est√° construyendo un modelo a partir de su conjunto de datos, ¬øc√≥mo obtendr√≠a los datos nunca antes vistos? Pozo Una forma es dividir el conjunto de datos en dos subconjuntos:

<br>

Conjunto de entrenamiento: un subconjunto para entrenar un modelo.
Conjunto de pruebas: un subconjunto para probar el modelo.

<br>

Un buen rendimiento en el equipo de prueba es un indicador √∫til de un buen rendimiento sobre los nuevos datos en general, asumiendo que:

<br>

El equipo de prueba es lo suficientemente grande.
No se hace trampa utilizando el mismo conjunto de pruebas una y otra vez.

El set de prueba es el que menos datos debe contener, ya que el entrenamiento es la prioridad

Conjunto de entrenamiento: Un subconjunto para entrenar un modelo.
Conjunto de prueba: Un subconjunto para probar el modelo entrenado.
Puedes imaginarte dividir el √∫nico conjunto de datos de la siguiente manera:

<br>

<img src="https://developers.google.com/static/machine-learning/crash-course/images/PartitionTwoSets.svg?hl=es-419">

<br>

Aseg√∫rate de que tu conjunto de prueba cumpla con las siguientes dos condiciones:

Sea lo suficientemente grande como para generar resultados significativos desde el punto de vista estad√≠stico.
Que sea representativo del conjunto de datos en su conjunto. En otras palabras, no elijas un conjunto de prueba con caracter√≠sticas diferentes a las del conjunto de entrenamiento.

Nunca uses datos de prueba para el entrenamiento. Si ves resultados sorprendentemente buenos en tus m√©tricas de evaluaci√≥n, puede ser una se√±al de que est√°s entrenando accidentalmente en el conjunto de prueba. Por ejemplo, una precisi√≥n alta puede indicar que los datos de prueba se filtraron en el conjunto de entrenamiento.

<br>

Para saber que tantos datos necesita nuestro modelo  para trabajar correctamente, podemos crear conjuntos de entrenamiento y prueba

<br>

Cuando el conjunto de entrenamiento es mas grande, la capacidad del modelo de predecir crece significativamente...
A mayor conjunto de prueba, mayor sera la confianza de los resultados

<br>

Es bueno tener un conjunto de datos MUY GRANDE
aproximadamente el 15%

<br>

***Ejercicio de Google***

<br>

[Practica!](https://developers.google.com/machine-learning/crash-course/training-and-test-sets/playground-exercise?hl=es-419)
Con este ejercicio podremos comprender un poco mas sobre los datos de entrenamiento...

<br>

***Flujo de trabajo***

<br>

<img src="https://developers.google.com/static/machine-learning/crash-course/images/WorkflowWithTestSet.svg?hl=es-419">

En la figura, "Ajustar el modelo" significa ajustar cualquier elemento del modelo que puedas imaginar, desde cambiar la tasa de aprendizaje hasta agregar o quitar atributos, o dise√±ar un modelo completamente nuevo desde cero. Al final de este flujo de trabajo, debes elegir el modelo que mejor se desempe√±e con respecto al conjunto de prueba.

Dividir el conjunto de datos en dos conjuntos es una buena idea, pero no una panacea. Para reducir en gran medida las posibilidades de sobreajuste, puedes particionar el conjunto de datos en los tres subconjuntos que se muestran en la siguiente figura:

<br>

<img src="https://developers.google.com/static/machine-learning/crash-course/images/PartitionThreeSets.svg?hl=es-419">

<br>

Usa el conjunto de validaci√≥n para evaluar los resultados del conjunto de entrenamiento. A continuaci√≥n, usa el conjunto de prueba para verificar la evaluaci√≥n despu√©s de que el modelo haya "pasado" el conjunto de validaci√≥n. En la siguiente figura, se muestra este nuevo flujo de trabajo:

<br>

<img src="https://developers.google.com/static/machine-learning/crash-course/images/WorkflowWithValidationSet.svg?hl=es-419">

<br>

***En este flujo de trabajo mejorado, sucede lo siguiente:***

<br>

Elige el modelo que mejor se desempe√±e con el conjunto de validaci√≥n.
Vuelve a verificar el modelo con el conjunto de prueba.
Este flujo de trabajo es m√°s eficaz porque crea menos exposiciones al conjunto de prueba.

<br>

***Ejercicio: (ir al archivo *VALIDACION Y SETS DE DATOS* y completarlo)***

<br>

***Ingenier√≠a de atributos***

<br>

C√≥mo asignar valores num√©ricos
Los datos de n√∫mero entero y de punto flotante no necesitan una codificaci√≥n especial porque se pueden multiplicar por un peso num√©rico. Como se sugiere en la Figura 2, convertir el valor entero sin procesar 6 en el valor de atributo 6.0 es sencillo:

<br>

<img src="https://developers.google.com/static/machine-learning/crash-course/images/FloatingPointFeatures.svg?hl=es-419">

<br>

Asignaci√≥n de valores categ√≥ricos
Los atributos categ√≥ricos tienen un conjunto discreto de valores posibles. Por ejemplo, podr√≠a haber una funci√≥n llamada street_name con opciones que incluyan las siguientes:


{'Charleston Road', 'North Shoreline Boulevard', 'Shorebird Way', 'Rengstorff Avenue'}
Dado que los modelos no pueden multiplicar strings por los pesos aprendidos, usamos la ingenier√≠a de atributos para convertir strings en valores num√©ricos.

Para ello, definimos una asignaci√≥n de los valores de los atributos, a los que nos referiremos como vocabulario de valores posibles, a n√∫meros enteros. Dado que no todas las calles del mundo aparecer√°n en nuestro conjunto de datos, podemos agrupar todas las dem√°s calles en una categor√≠a general llamada "otras", que se conoce como un bucket OOV (fuera del vocabulario).

Mediante este enfoque, podemos asignar nombres de calles a n√∫meros de la siguiente manera:

asignar Charleston Road a 0
asignar North Shoreline Boulevard a 1
asignar Shorebird Way a 2
asignar Rengstorff Avenue a 3
asignar todo lo dem√°s (OOV) a 4
Sin embargo, si incorporamos estos n√∫meros √≠ndice directamente en nuestro modelo, impondr√° algunas restricciones que podr√≠an ser problem√°ticas:

Aprenderemos un peso √∫nico que se aplique a todas las calles. Por ejemplo, si aprendemos un peso de 6 para street_name, lo multiplicaremos por 0 para Charleston Road, por 1 para North Shoreline Boulevard, por 2 para Shorebird Way y as√≠ sucesivamente. Considera un modelo que prediga el precio de las casas usando street_name como atributo. Es poco probable que haya un ajuste lineal del precio basado en el nombre de la calle. Adem√°s, esto supondr√° que ordenaste las calles seg√∫n el precio promedio de las casas. Nuestro modelo necesita la flexibilidad de aprender los diferentes pesos para cada calle, que se agregar√°n al precio estimado con los otros atributos.

No estamos contemplando los casos en los que street_name puede tener varios valores. Por ejemplo, muchas casas se encuentran en la esquina de dos calles y no hay forma de codificar esa informaci√≥n en el valor street_name si este contiene un solo √≠ndice.

Para quitar ambas restricciones, podemos crear un vector binario para cada atributo categ√≥rico de nuestro modelo que represente valores de la siguiente manera:

En el caso de los valores que se aplican al ejemplo, establece los elementos correspondientes al vector en 1.
Establecer todos los dem√°s elementos en 0.
La longitud de este vector es igual a la cantidad de elementos en el vocabulario. Esta representaci√≥n se denomina codificaci√≥n one-hot cuando un √∫nico valor es 1 y codificaci√≥n multi-hot cuando varios valores son 1.

La figura 3 ilustra una codificaci√≥n one-hot de una calle determinada: Shorebird Way. El elemento del vector binario de Shorebird Way tiene un valor de 1, mientras que los elementos de todas las dem√°s calles tienen un valor de 0.

<br>

<img src="https://developers.google.com/static/machine-learning/crash-course/images/OneHotEncoding.svg?hl=es-419">

<br>

Este enfoque crea de manera efectiva una variable booleana para cada valor de atributo (p.ej., nombre de la calle). En este caso, si una casa se encuentra en Shorebird Way, el valor binario es solo 1 para Shorebird Way. Por lo tanto, el modelo utiliza solo el peso para la calle Shorebird Way.

Del mismo modo, si una casa se encuentra en la esquina de dos calles, entonces dos valores binarios se establecen en 1, y el modelo usa ambos pesos respectivos.

# Representaci√≥n: Limpieza de datos <p id="representacion">

Los manzanos producen una mezcla de frutas excelentes y gusanos. Sin embargo, las manzanas que se muestran en los supermercados refinados son frutas 100% perfectas. Entre el huerto y el supermercado, alguien pasa mucho tiempo quitando las manzanas en mal estado o lanzando un poco de cera sobre las que se pueden recuperar. Como ingeniero de AA, dedicar√°s una gran cantidad de tu tiempo a desechar ejemplos malos y limpiar los que se pueden recuperar. Incluso unas pocas "manzanas en mal estado" pueden arruinar un gran conjunto de datos.

Ajusta valores de atributos
Escalamiento significa convertir los valores de atributos de punto flotante de su rango natural (por ejemplo, 100 a 900) al rango est√°ndar (por ejemplo, 0 a 1 o -1 a +1). Si un conjunto de atributos consiste en una sola funci√≥n, el escalamiento proporciona poco o ning√∫n beneficio pr√°ctico. Sin embargo, si un conjunto de atributos consta de varios atributos, el escalamiento de atributos proporciona los siguientes beneficios:

Ayuda a que el descenso de gradientes converja m√°s r√°pidamente.
Ayuda a evitar la "trampa de NaN", en la que un n√∫mero del modelo se convierte en un NaN (p.ej., cuando un valor excede el l√≠mite de precisi√≥n de punto flotante durante el entrenamiento) y, debido a operaciones matem√°ticas, el resto de los n√∫meros del modelo finalmente se convierte en NaN.
Permite que el modelo aprenda las ponderaciones correspondientes para cada atributo. Sin el ajuste de atributos, el modelo les prestar√° demasiada atenci√≥n a los atributos que tienen un rango m√°s amplio.
No es necesario que asignes el mismo ajuste de escala a cada atributo de punto flotante. No suceder√° nada terrible si el Atributo A se escala de -1 a +1, mientras que el Atributo B se ajusta de -3 a +3. Sin embargo, tu modelo reaccionar√° mal si el Atributo B se escala de 5,000 a 100,000.

***Manejo de valores at√≠picos extremos***

<br>

El siguiente gr√°fico representa un atributo llamado roomsPerPerson del conjunto de datos Viviendas de California. El valor de roomsPerPerson se dividi√≥ dividiendo la cantidad total de habitaciones en un √°rea por la poblaci√≥n en esa √°rea. El gr√°fico muestra que la gran mayor√≠a de √°reas en California tiene una o dos habitaciones por persona. Pero veamos el eje X.

<br>

<img src="https://developers.google.com/static/machine-learning/crash-course/images/ScalingNoticingOutliers.svg?hl=es-419">

<br>

entonces:

<br>

<img src="https://developers.google.com/static/machine-learning/crash-course/images/ScalingClipping.svg?hl=es-419">

<br>

El recorte del valor del atributo en 4.0 no significa que ignoremos todos los valores superiores a 4.0. En cambio, significa que todos los valores que eran superiores a 4.0 ahora se convierten en 4.0. Esto explica la elevaci√≥n extra√±a en 4.0. A pesar de esa elevaci√≥n, el conjunto de atributos ajustado ahora es m√°s √∫til que los datos originales.

<br>

En el conjunto de datos, latitude es un valor de punto flotante. Sin embargo, no tiene sentido representar latitude como un atributo de punto flotante en nuestro modelo. Eso se debe a que no existe una relaci√≥n lineal entre la latitud y los valores de las viviendas. Por ejemplo, las casas en la latitud 35 no son 
 m√°s costosas (o menos costosas) que las casas en la latitud 34. Sin embargo, las latitudes individuales probablemente son un muy buen predictor de los valores de casas.

Para que la latitud sea un predictor √∫til, debemos dividir las latitudes en discretizaciones, como se sugiere en la siguiente figura:

<br>

<img src="https://developers.google.com/static/machine-learning/crash-course/images/ScalingBinningPart2.svg?hl=es-419">

<br>

En lugar de tener un atributo de punto flotante, ahora tenemos 11 atributos booleanos distintos (LatitudeBin1, LatitudeBin2, ..., LatitudeBin11). Tener 11 atributos independientes es algo poco elegante, por lo que hay que unirlos en un solo vector de 11 elementos. Esto nos permitir√° representar la latitud 37.4 de la siguiente manera:

`[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]`


Gracias a la discretizaci√≥n, nuestro modelo ahora puede aprender pesos completamente diferentes para cada latitud.


# COMBINACIONES DE ATRIBUTOS <p id="combinacion">
***Codificaci√≥n de no linealidad***

<br>

<img src='https://developers.google.com/machine-learning/crash-course/images/LinearProblem1.png?hl=es-419'>

<br>

¬øEs un problema lineal?

¬øPuedes dibujar una l√≠nea que separe los √°rboles enfermos de los sanos? Claro. Este es un problema lineal. La l√≠nea no ser√° perfecta. Uno o dos √°rboles enfermos pueden estar del lado "sano", pero la l√≠nea ser√° un buen predictor.

Ahora, observe la siguiente figura:

<img src="https://developers.google.com/machine-learning/crash-course/images/LinearProblem2.png?hl=es-419">
¬øEs un problema lineal?

¬øPuedes trazar una sola l√≠nea recta que separe los √°rboles enfermos de los sanos? No, no puedes. Este es un problema no lineal. Cualquier l√≠nea que dibujes ser√° un predictor deficiente del estado de los √°rboles.

<img src="https://developers.google.com/machine-learning/crash-course/images/LinearProblemNot.png?hl=es-419">

Para resolver el problema no lineal que se muestra en la Figura 2, crea una combinaci√≥n de atributos. Una combinaci√≥n de atributos es un atributo sint√©tico que codifica la no linealidad en el espacio de los atributos al multiplicar dos o m√°s atributos de entrada. (El t√©rmino combinaci√≥n proviene de productos cruzados). Creemos una combinaci√≥n de atributos llamada x3 mediante la combinacion `x1` y `x2`
`x3 = x1*x2`


Tratamos esta combinaci√≥n de atributos x3 como cualquier otro atributo. La f√≥rmula lineal pasa a ser la siguiente:

`y=b+w1*x1+w2*x2+w3*x3`

Un algoritmo lineal puede aprender un peso para `w3`
del mismo modo que para  `w1` y `w2` 
En otras palabras, aunque `w3` codifica informaci√≥n no lineal, no necesitas cambiar la forma en la que se entrena el modelo lineal para determinar el valor de `w3`

Tipos de combinaciones de atributos
Es posible crear muchos tipos de combinaciones de atributos diferentes. Por ejemplo:

[A X B]: Una combinaci√≥n de atributos formada al multiplicar los valores de dos atributos.
[A x B x C x D x E]: Una combinaci√≥n de atributos formada al multiplicar los valores de cinco atributos.
[A x A]: Una combinaci√≥n de atributos formada al elevar al cuadrado un solo atributo.
Gracias al descenso de gradientes estoc√°stico, los modelos lineales se pueden entrenar de manera eficiente. En consecuencia, la complementaci√≥n de los modelos lineales ajustados con combinaciones de atributos ha sido tradicionalmente una forma eficiente de entrenar conjuntos de datos de escala masiva.


# Vectores de una sola combinacion <p id="vectores">

Hasta ahora, nos hemos enfocado en la combinaci√≥n de dos atributos de punto flotante individuales. En la pr√°ctica, los modelos de aprendizaje autom√°tico rara vez abarcan atributos continuos. Sin embargo, los modelos de aprendizaje autom√°tico suelen cruzar vectores de atributos one-hot. Piensa en combinaciones de atributos de vectores de un solo 1 como conjunciones l√≥gicas. Por ejemplo, supongamos que tenemos dos atributos: pa√≠s e idioma. Una codificaci√≥n one-hot de cada una genera vectores con atributos binarios que pueden interpretarse como country=USA, country=France o language=English, language=Spanish. Luego, si realizas una combinaci√≥n de atributos de estas codificaciones de un solo 1, obtienes atributos binarios que pueden interpretarse como conjunciones l√≥gicas, como las siguientes:


  country:usa AND language:spanish
Como otro ejemplo, supongamos que discretizas latitud y longitud, lo que produce vectores de atributos de un solo 1 con cinco elementos. Por ejemplo, una latitud y longitud determinadas se pueden representar de la siguiente manera:


  binned_latitude = [0, 0, 0, 1, 0]
  binned_longitude = [0, 1, 0, 0, 0]
Supongamos que creas una combinaci√≥n de atributos de estos dos vectores de atributos:


  binned_latitude X binned_longitude
Esta combinaci√≥n de atributos es un vector de un solo 1 con 25 elementos (24 ceros y 1 uno). El √∫nico 1 en la combinaci√≥n identifica una conjunci√≥n en particular de latitud y longitud. El modelo puede aprender asociaciones particulares sobre esa conjunci√≥n.

Supongamos que discretizamos latitud y longitud de manera mucho m√°s amplia, de la siguiente manera:


binned_latitude(lat) = [
  0  < lat <= 10
  10 < lat <= 20
  20 < lat <= 30
]

binned_longitude(lon) = [
  0  < lon <= 15
  15 < lon <= 30
]
La creaci√≥n de una combinaci√≥n de atributos de esos discretizaciones groseras genera un atributo sint√©tico con los siguientes significados:


binned_latitude_X_longitude(lat, lon) = [
  0  < lat <= 10 AND 0  < lon <= 15
  0  < lat <= 10 AND 15 < lon <= 30
  10 < lat <= 20 AND 0  < lon <= 15
  10 < lat <= 20 AND 15 < lon <= 30
  20 < lat <= 30 AND 0  < lon <= 15
  20 < lat <= 30 AND 15 < lon <= 30
]
Ahora supongamos que nuestro modelo necesita predecir qu√© tan satisfechos estar√°n los due√±os de perros con los perros en funci√≥n de dos atributos:

Tipo de comportamiento (ladrido, llanto, acurrucaci√≥n, etc.)
Hora del d√≠a
Si compilamos una combinaci√≥n de atributos a partir de estos dos atributos:


  [behavior type X time of day]
obtendremos una capacidad de predicci√≥n mucho mayor que cualquiera de las funciones. Por ejemplo, si un perro llora (de felicidad) a las 5:00 p.m. cuando el due√±o regresa del trabajo, probablemente ser√° un excelente predictor positivo de la satisfacci√≥n del propietario. Llorar (tal vez con tristeza) a las 3:00 a.m. cuando el propietario estaba durmiendo profundamente probablemente sea un fuerte predictor negativo de la satisfacci√≥n del propietario.

Los alumnos lineales se ajustan bien a los datos masivos. Usar combinaciones de atributos en conjuntos de datos masivos es una estrategia eficiente para aprender modelos muy complejos. Las redes neuronales proporcionan otra estrategia
[Practica!](https://developers.google.com/machine-learning/crash-course/feature-crosses/playground-exercises?hl=es-419)

<br>

***Combinaciones de atributos: Ejercicio de programaci√≥n***

<br>

Haremos un ejuercico muy util, ve al archivo: `rEPRESENTATION_WITH_A_FEATURE_CROSS.ipynb`
[link](https://developers.google.com/machine-learning/crash-course/feature-crosses/programming-exercise?hl=es-419)

<br>

***Combinaciones de atributos: Comprueba tu comprensi√≥n***

<br>

[Comprueba tu comprensi√≥n](https://developers.google.com/machine-learning/crash-course/feature-crosses/check-your-understanding?hl=es-419)

# Regresi√≥n log√≠stica <p id="regresion">
En lugar de predecir exactamente 0 o 1, la regresi√≥n log√≠stica genera una probabilidad, un valor entre 0 y 1, exclusivo. Por ejemplo, considera un modelo de regresi√≥n log√≠stica para la detecci√≥n de spam. Si el modelo infiere un valor de 0.932 en un mensaje de correo electr√≥nico en particular, implica una probabilidad del 93.2% de que el mensaje sea spam. M√°s precisamente, significa que, en el l√≠mite de ejemplos de entrenamiento infinitos, el conjunto de ejemplos para los que el modelo predice 0.932 ser√° realmente spam el 93.2% de las veces, y el 6.8% restante no lo ser√°.

***Regresi√≥n log√≠stica: calcular una probabilidad ***
Muchos problemas requieren una estimaci√≥n de probabilidad como resultado. La regresi√≥n log√≠stica es un mecanismo extremadamente eficiente para calcular las probabilidades. En t√©rminos pr√°cticos, puedes usar la probabilidad que se muestra de cualquiera de las siguientes dos maneras:

"Tal como est√°"
Se convirti√≥ en una categor√≠a binaria.
Consideremos c√≥mo podemos usar la probabilidad ‚Äútal como est√°‚Äù. Supongamos que creamos un modelo de regresi√≥n log√≠stica para predecir la probabilidad de que un perro ladre durante la noche. A esa probabilidad la llamaremos:
`p(ladridos/noche)`
Si el modelo de regresi√≥n log√≠stica predice `p(ladridos/noche) =0.05`, el propietario de un perro deber√° despertarse durante aproximadamente un a√±o aproximadamente 18 veces:

`numero_noches = p(ladridos/noche) * noches`
<br>

`18 = 0.05 *365`

En muchos casos, asignar√°s el resultado de la regresi√≥n log√≠stica a la soluci√≥n a un problema de clasificaci√≥n binaria, en el que el objetivo es predecir correctamente una de dos etiquetas posibles (p.ej., "spam" o &no es spam?) Un m√≥dulo posterior se enfoca en eso.

Es posible que te preguntes c√≥mo un modelo de regresi√≥n log√≠stica puede garantizar un resultado que siempre se encuentre entre 0 y 1. A medida que sucede, una funci√≥n sigmoidea, definida de la siguiente manera, produce resultados que tienen esas mismas caracter√≠sticas:

`y= 1/1+e^(-z)`

La funci√≥n sigmoidea genera la siguiente representaci√≥n:

<img src="https://developers.google.com/machine-learning/crash-course/images/SigmoidFunction.png?hl=es-419">


Si `z` representa el resultado de la capa lineal de un modelo entrenado con regresi√≥n log√≠stica, producir√° un valor (una probabilidad) entre 0 y 1. En t√©rminos matem√°ticos:


# Clasificacion <p id="clasificaion">

<br>

***Clasificaci√≥n: Umbral ***

<br>

La regresi√≥n log√≠stica muestra una probabilidad. Puedes usar la probabilidad de que se muestre ‚Äútal como est√°‚Äù (por ejemplo, la probabilidad de que el usuario haga clic en este anuncio es 0.00023) o la convierte en un valor binario (por ejemplo, este correo electr√≥nico es spam).

Un modelo de regresi√≥n log√≠stica que muestra 0.9995 para un mensaje de correo electr√≥nico en particular predice que es muy probable que sea spam. Por el contrario, otro mensaje de correo electr√≥nico con una puntuaci√≥n de predicci√≥n de 0.0003 en el mismo modelo de regresi√≥n log√≠stica es muy probable que no sea spam. Sin embargo, ¬øqu√© ocurre con un mensaje de correo electr√≥nico con una puntuaci√≥n de predicci√≥n de 0.6? Para asignar un valor de regresi√≥n log√≠stica a una categor√≠a binaria, debes definir un umbral de clasificaci√≥n (tambi√©n llamado umbral de decisi√≥n). Un valor por encima de ese umbral indica "spam" un valor por debajo indica "no spam" Es tentador suponer que el umbral de clasificaci√≥n siempre debe ser 0.5, pero los umbrales dependen del problema y, por lo tanto, son valores que debes ajustar.

En las siguientes secciones, se analizan con m√°s detalle las m√©tricas que puedes usar para evaluar las predicciones de un modelo de clasificaci√≥n, as√≠ como el impacto del cambio del umbral de clasificaci√≥n en estas predicciones.

<br>

***Clasificaci√≥n: Verdadero o falso y positivo o negativo***

<br>

En esta secci√≥n, definiremos los componentes b√°sicos de las m√©tricas que usaremos para evaluar los modelos de clasificaci√≥n. Pero primero, una f√°bula:

```
F√°bula de Esopo: El ni√±o que grit√≥ lobo (comprimido)

Un joven pastor se aburre de cuidar el reba√±o del pueblo Para divertirse, grita, "¬°Lobo!", a pesar de que no hay un lobo a la vista. Los vecinos corren para proteger el reba√±o, pero se enojan mucho cuando se dan cuenta de que el ni√±o les estaba bromeando.

[Repite el p√°rrafo anterior N veces].

Una noche, el joven pastor ve un lobo real acerc√°ndose al reba√±o y grita: "¬°Lobo!". Los vecinos se niegan a ser enga√±ados otra vez y se quedan en sus casas. El hambriento lobo convierte el reba√±o en cortes de cordero. El pueblo est√° hambriento. Se produce un p√°nico.
```

Hagamos las siguientes definiciones:

"Lobo" es una clase positiva.
Ning√∫n lobo es una clase negativa.
Podemos resumir nuestro modelo de "predicci√≥n de lobos" con una matriz de confusi√≥n de 2 x 2 que muestra los cuatro resultados posibles:

<img src="./falso-positivo.png">


Un verdadero positivo es un resultado en el que el modelo predice correctamente la clase positiva. De manera similar, un verdadero negativo es un resultado en el que el modelo predice correctamente la clase negativa.

Un falso positivo es un resultado en el que el modelo predice de manera incorrecta la clase positiva. Y un falso negativo es un resultado en el que el modelo predice incorrectamente la clase negativa.

En las siguientes secciones, veremos c√≥mo evaluar los modelos de clasificaci√≥n mediante m√©tricas derivadas de estos cuatro resultados.

<br>

***Clasificaci√≥n: Precisi√≥n y recuperaci√≥n***

<br>

La precisi√≥n intenta responder a la siguiente pregunta:

`¬øQu√© proporci√≥n de identificaciones positivas fue correcta?`

[informacion](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall?hl=es-419)

<br>

***Precisi√≥n y recuperaci√≥n: una lucha incesante***

<br>

Para evaluar completamente la efectividad de un modelo, debes examinar la precisi√≥n y la recuperaci√≥n. Lamentablemente, la precisi√≥n y la recuperaci√≥n suelen ser tensas. Es decir, la mejora de la precisi√≥n suele reducir la recuperaci√≥n, y viceversa. Para explorar esta noci√≥n, observa la siguiente figura, que muestra 30 predicciones realizadas por un modelo de clasificaci√≥n de correo electr√≥nico. Las que se encuentran a la derecha del umbral de clasificaci√≥n se clasifican como "spam", mientras que las de la izquierda se clasifican como "no es spam".

[practica](https://developers.google.com/machine-learning/crash-course/classification/check-your-understanding-accuracy-precision-recall?hl=es-419)

<br>

***Clasificaci√≥n: Curva ROC y AUC***

<br>

[texto](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc?hl=es-419)

<br>

***ROC curve***

<br>

Una curva ROC representa TPR frente a FPR en diferentes umbrales de clasificaci√≥n. Al disminuir el umbral de clasificaci√≥n, se clasifican m√°s elementos como positivos, lo que aumenta tanto los falsos positivos como los verdaderos positivos. En la siguiente figura, se muestra una curva ROC t√≠pica.

<img src="https://developers.google.com/static/machine-learning/crash-course/images/ROCCurve.svg?hl=es-419">
Para calcular los puntos en una curva ROC, podr√≠amos evaluar un modelo de regresi√≥n log√≠stica muchas veces con diferentes umbrales de clasificaci√≥n, pero esto ser√≠a ineficiente. Afortunadamente, existe un algoritmo eficaz y basado en ordenamiento que puede proporcionarnos esta informaci√≥n, llamada AUC.

<br>

***AUC: √Årea bajo la curva ROC***

<br>

AUC significa "√°rea bajo la curva ROC". Es decir, el AUC mide el √°rea bidimensional completa debajo de la curva ROC completa (piensa en un c√°lculo integral) de (0,0) a (1,1).
<img src="https://developers.google.com/static/machine-learning/crash-course/images/AUC.svg?hl=es-419">
El AUC proporciona una medida agregada del rendimiento en todos los umbrales de clasificaci√≥n posibles. Una forma de interpretar el AUC es como la probabilidad de que el modelo clasifique un ejemplo positivo aleatorio m√°s alto que un ejemplo negativo aleatorio. Por ejemplo, en los siguientes ejemplos, que se ordenan de izquierda a derecha en orden ascendente con respecto a las predicciones de regresi√≥n log√≠stica:

<img src="https://developers.google.com/static/machine-learning/crash-course/images/AUCPredictionsRanked.svg?hl=es-419">

El AUC representa la probabilidad de que un ejemplo aleatorio positivo (verde) se posicione a la derecha de un ejemplo aleatorio negativo (rojo).

El AUC var√≠a en valor de 0 a 1. Un modelo cuyas predicciones son un 100% incorrectas tiene un AUC de 0.0; uno cuyas predicciones son un 100% correctas tiene un AUC de 1.0.

El AUC es conveniente por los siguientes dos motivos:

El AUC es invariable con respecto a la escala. Mide qu√© tan bien se clasifican las predicciones, en lugar de sus valores absolutos.
El AUC es invariable con respecto al umbral de clasificaci√≥n. Mide la calidad de las predicciones del modelo, independientemente del umbral de clasificaci√≥n elegido.
Sin embargo, ambos motivos tienen advertencias, que pueden limitar la utilidad del AUC en ciertos casos pr√°cticos:

La invariancia de escala no siempre es conveniente. Por ejemplo, a veces, realmente necesitamos resultados de probabilidad bien calibrados, y el AUC no nos dir√° eso.

La invariancia del umbral de clasificaci√≥n no siempre es conveniente. En los casos en los que hay grandes disparidades en el costo de falsos negativos en comparaci√≥n con los falsos positivos, puede ser cr√≠tico minimizar un tipo de error de clasificaci√≥n. Por ejemplo, cuando realizas una detecci√≥n de spam de correo electr√≥nico, es probable que quieras priorizar la minimizaci√≥n de los falsos positivos (incluso si eso genera un aumento significativo de los falsos negativos). El AUC no es una m√©trica √∫til para este tipo de optimizaci√≥n.

<br>

***Clasificaci√≥n: Sesgo de predicci√≥n***

<br>

Un sesgo de predicci√≥n distinto de cero indica que hay un error en alg√∫n lugar del modelo, ya que indica que el modelo no est√° bien acerca de la frecuencia con la que se producen etiquetas positivas.

Por ejemplo, supongamos que sabemos que, en promedio, el 1% de todos los correos electr√≥nicos son spam. Si no sabemos nada sobre un correo electr√≥nico determinado, debemos predecir que es probable que sea spam. Del mismo modo, un buen modelo de spam deber√≠a predecir, en promedio, que los correos electr√≥nicos tienen un 1% de probabilidades de ser spam. (En otras palabras, si promediamos las probabilidades predichas de que cada correo electr√≥nico individual sea spam, el resultado deber√≠a ser 1%). Si, en cambio, la predicci√≥n promedio del modelo es un 20% de probabilidades de ser spam, podemos concluir que muestra un sesgo de predicci√≥n.

Las posibles causas ra√≠z del sesgo de predicci√≥n son las siguientes:

1. **Conjunto de atributos incompleto:**
   - **Explicaci√≥n:** Si el conjunto de atributos utilizado para entrenar el modelo no abarca todas las caracter√≠sticas relevantes para la tarea, el modelo puede no capturar completamente la complejidad del problema.
   - **Efecto en el sesgo:** Puede llevar a que el modelo ignore aspectos importantes del fen√≥meno que est√° tratando de predecir, resultando en sesgo en las predicciones.

2. **Conjunto de datos ruidoso:**
   - **Explicaci√≥n:** Si el conjunto de datos contiene informaci√≥n incorrecta, inconsistente o no representativa del fen√≥meno que se est√° modelando, el modelo puede aprender patrones no v√°lidos.
   - **Efecto en el sesgo:** El ruido en los datos puede llevar a que el modelo haga generalizaciones incorrectas y, por lo tanto, introduzca sesgo en las predicciones.

3. **Canalizaci√≥n con errores:**
   - **Explicaci√≥n:** La canalizaci√≥n (pipeline) de datos y el preprocesamiento pueden introducir errores si no se realizan correctamente. Por ejemplo, escalado incorrecto, normalizaci√≥n inadecuada u otros errores en la manipulaci√≥n de datos.
   - **Efecto en el sesgo:** Errores en la canalizaci√≥n pueden afectar la calidad de los datos de entrada, lo que a su vez afecta la capacidad del modelo para aprender de manera precisa.

4. **Muestra de entrenamiento sesgada:**
   - **Explicaci√≥n:** Si la muestra utilizada para entrenar el modelo no es representativa de la poblaci√≥n general, el modelo puede aprender patrones espec√≠ficos de la muestra que no se aplican de manera general.
   - **Efecto en el sesgo:** Puede resultar en un modelo que no generaliza bien a datos nuevos y muestra sesgo hacia los patrones presentes en la muestra de entrenamiento.

5. **Regularizaci√≥n demasiado intensa:**
   - **Explicaci√≥n:** La regularizaci√≥n es una t√©cnica utilizada para prevenir el sobreajuste al penalizar coeficientes grandes en el modelo. Sin embargo, si la regularizaci√≥n es demasiado intensa, puede llevar a que el modelo simplifique en exceso, ignorando patrones importantes.
   - **Efecto en el sesgo:** Una regularizaci√≥n excesiva puede introducir sesgo al forzar al modelo a ser demasiado simplista y perder detalles importantes en los datos.

Est√° solucionando el s√≠ntoma en lugar de la causa.
Creaste un sistema m√°s fr√°gil que ahora debes mantener actualizado.
Si es posible, evita las capas de calibraci√≥n. Los proyectos que usan capas de calibraci√≥n tienden a depender de ellas, ya que usan capas de calibraci√≥n para corregir todos los senos del modelo. En √∫ltima instancia, mantener las capas de calibraci√≥n puede convertirse en una pesadilla.

***Agrupamiento y sesgo de predicci√≥n***
La regresi√≥n log√≠stica predice un valor entre 0 y 1. Sin embargo, todos los ejemplos etiquetados son exactamente 0 (lo que significa, por ejemplo, &no es spam) o exactamente 1 (que significa, por ejemplo, &spam). Por lo tanto, cuando examinas el sesgo de predicci√≥n, no puedes determinar con exactitud el sesgo de predicci√≥n en funci√≥n de un solo ejemplo. Debes examinar el sesgo de predicci√≥n en un bucket de ejemplos. Es decir, el sesgo de predicci√≥n para la regresi√≥n log√≠stica solo tiene sentido cuando se agrupan suficientes ejemplos como para poder comparar un valor previsto (por ejemplo, 0.392) con los valores observados (por ejemplo, 0.394).

Puedes formar dep√≥sitos de las siguientes maneras:

- Divide linealmente las predicciones objetivo.
- Forma cuantiles.
Considera el siguiente gr√°fico de calibraci√≥n de un modelo en particular. Cada punto representa un bucket de 1,000 valores. Los ejes tienen los siguientes significados:

El eje x representa el promedio de valores que el modelo predijo para ese bucket.
El eje y representa el promedio real de los valores en el conjunto de datos para ese bucket.
Ambos ejes son escalas logar√≠tmicas.

<img src='https://developers.google.com/static/machine-learning/crash-course/images/BucketingBias.svg?hl=es-419'>
¬øPor qu√© las predicciones son tan deficientes solo para parte del modelo? Estas son algunas posibilidades:

El conjunto de entrenamiento no representa de forma adecuada ciertos subconjuntos del espacio de datos.
Algunos subconjuntos de datos son m√°s ruidosos que otros.
El modelo est√° regularizado en exceso. (Considera reducir el valor de lambda).

***Clasificaci√≥n binaria: ejercicio de programaci√≥n***
En el siguiente [ejercicio](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/binary_classification.ipynb?utm_source=mlcc&utm_campaign=colab-external&utm_medium=referral&utm_content=binary_classification_tf2-colab&hl=es-419), explorar√°s la clasificaci√≥n binaria en TensorFlow:

El archivo se llama: Binary_Classification


# Regularizaci√≥n para lograr dispersi√≥n <p id="regularizacion">

<br>

***Regularizaci√≥n para lograr dispersi√≥n: Regularizaci√≥n L1***

<br>

Los vectores dispersos a menudo contienen muchas dimensiones. Cuando se crea una combinaci√≥n de atributos, se generan incluso m√°s dimensiones. Dados estos vectores de atributos de dimensiones altas, el tama√±o del modelo puede aumentar enormemente y requerir grandes cantidades de RAM.

En un vector disperso de dimensiones altas, ser√≠a bueno motivar a los pesos a que se reduzcan exactamente a 0 siempre que sea posible. Un peso de exactamente 0 b√°sicamente quita el atributo correspondiente del modelo. Cuando se extraen atributos, se ahorrar√° RAM y es posible que se reduzca el ruido en el modelo.

Por ejemplo, considera un conjunto de datos de viviendas que abarque no solo California, sino todo el mundo. Cuando se agrupa la latitud del mundo en minutos (60 minutos por grado), se obtienen alrededor de 10,000 dimensiones en una codificaci√≥n dispersa; la longitud global en minutos da alrededor de 20,000 dimensiones. Una combinaci√≥n de estos dos atributos dar√≠a como resultado 200,000,000 dimensiones. Muchas de esas 200,000,000 dimensiones representan √°reas con una residencia tan limitada (por ejemplo, el medio del oc√©ano) que ser√≠a dif√≠cil usar esos datos para generalizar de manera efectiva. Ser√≠a un poco absurdo pagar el costo de RAM de almacenar estas dimensiones innecesarias. Por lo tanto, ser√≠a bueno llevar los pesos de las dimensiones sin sentido a exactamente 0, lo que nos permitir√≠a evitar pagar el costo de almacenamiento de estos coeficientes del modelo en el momento de la inferencia.

Es posible que podamos codificar esta idea en el problema de optimizaci√≥n realizado durante el entrenamiento si agregamos un t√©rmino de regularizaci√≥n elegido de forma adecuada.

¬øLa regularizaci√≥n L2 puede completar esta tarea? Lamentablemente, no. La regularizaci√≥n L2 ayuda a reducir el tama√±o de los pesos, pero no los lleva a exactamente 0.0.

Una idea alternativa ser√≠a crear un t√©rmino de regularizaci√≥n que penalice el recuento de valores de coeficiente distintos de cero en un modelo. El aumento de este recuento solo estar√≠a justificado si hubiera una ganancia suficiente en la capacidad del modelo para ajustar los datos. Lamentablemente, si bien este enfoque basado en el conteo es intuitivamente atractivo, convertir√≠a nuestro problema de optimizaci√≥n convexa en un problema de optimizaci√≥n no convexa. Por lo tanto, esta idea, conocida como regularizaci√≥n L0, no resulta √∫til en la pr√°ctica.

Sin embargo, existe un t√©rmino de regularizaci√≥n llamado regularizaci√≥n L1 que sirve como una aproximaci√≥n a L0, pero tiene la ventaja de ser convexa y, por lo tanto, eficiente para su procesamiento. Entonces, podemos usar la regularizaci√≥n L1 para llevar los coeficientes sin informaci√≥n √∫til en nuestro modelo a exactamente 0 y, por lo tanto, ahorrar RAM durante la inferencia.

**Diferencias entre regularizaciones L1 y L2**
L2 y L1 penalizan los pesos de forma diferente:

L2 penaliza peso2.
L1 penaliza |peso|.
En consecuencia, L2 y L1 tienen diferentes derivadas:

La derivada de L2 es 2 * peso.
La derivada de L1 es k (una constante cuyo valor es independiente del peso).
Se puede pensar en la derivada de L2 como una fuerza que quita x% del peso todo el tiempo. Como ya sab√≠a Zen√≥n, incluso si quitas un porcentaje x de un n√∫mero miles de millones de veces, el n√∫mero disminuido nunca alcanzar√° el cero. (Zen√≥n no estaba familiarizado con las limitaciones de precisi√≥n del punto flotante, que podr√≠an producir exactamente cero). En cualquier caso, L2 normalmente no lleva los pesos a cero.

Se puede pensar en la derivada de L1 como una fuerza que resta una constante de la ponderaci√≥n todo el tiempo. Sin embargo, gracias a los valores absolutos, L1 tiene una discontinuidad en 0, que hace que las restas que superen 0 queden en cero. Por ejemplo, si la resta fuerza un peso de +0.1 a -0.2, L1 establecer√° el peso en exactamente 0. ¬°Eureka! L1 llev√≥ el peso a cero.

La regularizaci√≥n L1, al penalizar el valor absoluto de todos los pesos, es muy eficiente para los modelos amplios.

Ten en cuenta que esta descripci√≥n es verdadera para un modelo unidimensional.
[ver](https://developers.google.com/machine-learning/crash-course/regularization-for-sparsity/l1-regularization?hl=es-419)

<br>

***Regularizaci√≥n para lograr dispersi√≥n: Ejercicio de Playground***

<br>

*Examen de la regularizaci√≥n L1*
Este ejercicio contiene un conjunto de datos de entrenamiento peque√±o y un poco ruidoso. En este tipo de escenario, el sobreajuste es un problema real. La regularizaci√≥n podr√≠a ayudar, pero ¬øqu√© forma de regularizaci√≥n?

Este ejercicio consta de cinco tareas relacionadas. Para simplificar las comparaciones en las cinco tareas, ejecuta cada tarea en una pesta√±a independiente. Ten en cuenta que el espesor de las l√≠neas que conectan ATRIBUTOS con SALIDA representa las ponderaciones relativas de cada atributo.

[patio de jeugos](https://developers.google.com/machine-learning/crash-course/regularization-for-sparsity/playground-exercise?hl=es-419)
[examen](https://developers.google.com/machine-learning/crash-course/regularization-for-sparsity/check-your-understanding?hl=es-419)

En definitiva l1 es mas util a la hora de hacer un modelo menos pesado

# Redes neuronales: Estructura <p id="redesneuronales">

<br>

***Redes neuronales: Estructura***

<br>

Si recuerdas la unidad [Combinaciones](https://developers.google.com/machine-learning/crash-course/feature-crosses/video-lecture?hl=es-419) de atributos, el siguiente problema de clasificaci√≥n no es lineal:
<img src="https://developers.google.com/machine-learning/crash-course/images/FeatureCrosses1.png?hl=es-419">
‚ÄúNo lineal‚Äù significa que no puedes predecir con exactitud una etiqueta con un modelo con la forma b + w1x1 + w2x2
En otras palabras, la superficie de decisi√≥n no es una l√≠nea. Anteriormente, observamos las [Combinaciones de atributos](https://developers.google.com/machine-learning/crash-course/feature-crosses/video-lecture?hl=es-419) como un enfoque posible para modelar problemas no lineales.

Ahora considera el siguiente conjunto de datos:

<img src="https://developers.google.com/machine-learning/crash-course/images/NonLinearSpiral.png?hl=es-419">

El conjunto de datos que se muestra en la figura 2 no se puede resolver con un modelo lineal.

Para ver c√≥mo las redes neuronales pueden ayudar con problemas no lineales, comencemos por representar un modelo lineal como un gr√°fico:

<img src="https://developers.google.com/static/machine-learning/crash-course/images/linear_net.svg?hl=es-419">
Cada c√≠rculo azul representa un atributo de entrada, y el c√≠rculo verde representa la suma ponderada de las entradas.

¬øC√≥mo podemos modificar este modelo para mejorar su capacidad de abordar problemas no lineales?

*Capas ocultas*

<br>

En el modelo que se muestra en el siguiente gr√°fico, agregamos una capa oculta de valores intermedios. Cada nodo amarillo en la capa oculta es una suma ponderada de los valores del nodo de entrada azul. El resultado es una suma ponderada de los nodos amarillos.
<img src="https://developers.google.com/static/machine-learning/crash-course/images/1hidden.svg?hl=es-419">

Este modelo es lineal? S√≠, su resultado sigue siendo una combinaci√≥n lineal de sus entradas.

En el modelo que se muestra en el siguiente gr√°fico, agregamos una segunda capa oculta de sumas ponderadas.

<img src="https://developers.google.com/static/machine-learning/crash-course/images/2hidden.svg?hl=es-419">
¬øEste modelo es lineal? S√≠, lo es. Cuando expresas el resultado como una funci√≥n de la entrada y lo simplificas, obtienes otra suma ponderada de las entradas. Esta suma no modelar√° el problema no lineal de la Figura 2.

*Funciones de activaci√≥n*
<br>
Para modelar un problema no lineal, podemos introducir directamente una no linealidad. Podemos canalizar cada nodo de capa oculta a trav√©s de una funci√≥n no lineal.

En el modelo que se muestra en el siguiente grafo, una funci√≥n no lineal transforma el valor de cada nodo en la capa 1 oculta antes de pasar a las sumas ponderadas de la siguiente capa. Esta funci√≥n no lineal se denomina funci√≥n de activaci√≥n.

<img src="https://developers.google.com/static/machine-learning/crash-course/images/activation.svg?hl=es-419">


Ahora que hemos agregado una funci√≥n de activaci√≥n, agregar capas tiene m√°s impacto. Apilar no linealidades sobre no linealidades nos permite modelar relaciones muy complicadas entre las entradas y las salidas previstas. En resumen, cada capa aprende de manera eficaz una funci√≥n m√°s compleja y de nivel superior sobre las entradas sin procesar. Si deseas tener m√°s intuici√≥n de c√≥mo funciona esto, consulta la [excelente entrada de blog de Chris Olah.](https://colah.github.io/posts/2014-03-NN-Manifolds-Topology/)

*Funciones de activaci√≥n comunes*
La siguiente funci√≥n de activaci√≥n sigmoidea convierte la suma ponderada en un valor entre 0 y 1.

f(x) = 1/1+e ^(-x)

Graficado:

<img src="https://developers.google.com/static/machine-learning/crash-course/images/sigmoid.svg?hl=es-419">
La siguiente funci√≥n de activaci√≥n de unidad lineal rectificada (o ReLU, por sus siglas en ingl√©s) a menudo funciona mejor que una funci√≥n suave, como la sigmoide, y es mucho m√°s f√°cil de calcular.

f(x) = max(0,x)

La superioridad de la ReLU se basa en resultados emp√≠ricos, probablemente debido a que ReLU tiene un rango de capacidad de respuesta m√°s √∫til. La capacidad de respuesta de una funci√≥n sigmoidea se reduce relativamente r√°pido en ambos lados.

<img src="https://developers.google.com/static/machine-learning/crash-course/images/relu.svg?hl=es-419">

De hecho, cualquier funci√≥n matem√°tica puede servir como funci√≥n de activaci√≥n. Supongamos que `o` representa nuestra funci√≥n de activaci√≥n (Relu, Sigmoid o cualquier otra). En consecuencia, el valor de un nodo en la red se proporciona mediante la siguiente f√≥rmula:
`o(w*x+b)`

TensorFlow proporciona compatibilidad [lista para usar en muchas funciones de activaci√≥n](https://www.tensorflow.org/api_docs/python/tf/nn). Puedes encontrar estas funciones de activaci√≥n en la lista de wrappers para operaciones de redes neuronales b√°sicas de TensorFlow. Sin embargo, recomendamos comenzar con ReLU.

<br>

**resumen**

<br>

Ahora, nuestro modelo tiene todos los componentes est√°ndar de lo que las personas generalmente significan cuando dicen &red neuronal:

Un conjunto de nodos, an√°logos a las neuronas, organizados en capas.
Un conjunto de pesos que representan las conexiones entre cada capa de la red neuronal y la capa inferior. La capa inferior puede ser otra capa de la red neuronal u otro tipo de capa.
Un conjunto de sesgos, uno para cada nodo.
Una funci√≥n de activaci√≥n que transforma el resultado de cada nodo en una capa. Las diferentes capas pueden tener diferentes funciones de activaci√≥n.

<br>

***Redes neuronales: Ejercicios de Playground***

<br>

[ejercicio](https://developers.google.com/machine-learning/crash-course/introduction-to-neural-networks/playground-exercises?hl=es-419 )

<br>

*ejercicio de codigo*

<br>

[click para ejercucui](https://developers.google.com/machine-learning/crash-course/introduction-to-neural-networks/programming-exercise?hl=es-419)
<br>
El nombre del archivo es Intro_to_Neural_Nets.ipynb